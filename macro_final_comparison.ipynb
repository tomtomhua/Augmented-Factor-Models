{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas_datareader import data\n",
    "from datetime import datetime\n",
    "from numpy.linalg import inv\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor,LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from skpp import ProjectionPursuitRegressor\n",
    "\n",
    "import MyHuberLoss\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_month = pd.read_csv('data/8-agg-factors.csv').dropna().drop(columns='Data')\n",
    "y_month = pd.read_csv('data/131-macrodat.csv',header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions defined for use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def mse(data, pred):\n",
    "    return(sum(data - pred)**2/len(data))\n",
    "\n",
    "def in_sample_cv(X,y,model,cv = 5):\n",
    "    kf = KFold(n_splits=cv,random_state=0)\n",
    "    mse_cv = list()\n",
    "    for train, _ in kf.split(X):\n",
    "        mse_pred = mse(y[train],model.fit(X.iloc[train],y[train]).predict(X.iloc[train]))\n",
    "        mse_cv.append(mse_pred)\n",
    "    return(np.mean(mse_cv))\n",
    "\n",
    "def out_sample_cv(X,y,model,cv = 5):\n",
    "    kf = KFold(n_splits=cv,random_state=0)\n",
    "    mse_cv = list()\n",
    "    for train, test in kf.split(X):\n",
    "        mse_pred = mse(y[test],model.fit(X.iloc[train],y[train]).predict(X.iloc[test]))\n",
    "        mse_cv.append(mse_pred)\n",
    "    return(np.mean(mse_cv))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_sample_cv_parallel(X,y,model,cv = 5):\n",
    "    kf = KFold(n_splits=cv,random_state=0)\n",
    "    \n",
    "    def pred(train,test):\n",
    "        return(mse(y[test],model.fit(X.iloc[train],y[train]).predict(X.iloc[test])))\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    mse_cv = Parallel(n_jobs=5)(delayed(pred)(train,test) for train,test in kf.split(X))\n",
    "    return(np.mean(mse_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_basis(series,k):\n",
    "    N = len(series)\n",
    "    # t from 1 to N\n",
    "    t = np.linspace(1,N,N)\n",
    "    out_list = list()\n",
    "    for index in range(1,k+1):\n",
    "        # derieve numerial result of ai, bi (intergration) for fourier basis\n",
    "        cosxfx = np.cos(2*index*t*np.pi/N)*np.array(series)\n",
    "        sinxfx = np.sin(2*index*t*np.pi/N)*np.array(series)\n",
    "        ai = 2/N*sum(cosxfx - cosxfx[0]/2 - cosxfx[-1]/2)\n",
    "        bi = 2/N*sum(sinxfx - sinxfx[0]/2 - sinxfx[-1]/2)\n",
    "        basis_i = ai*np.cos(2*np.pi*index*t/N)+bi*np.sin(2*np.pi*index*t/N)\n",
    "        out_list.append(basis_i)\n",
    "    return(out_list)\n",
    "\n",
    "def polynomial_basis(series,k):\n",
    "    out_list = list()\n",
    "    for index in range(1,k+1):\n",
    "        out_list.append(series**index)\n",
    "    return(out_list)\n",
    "\n",
    "def basis_transform(X,model = polynomial_basis,k = 5):\n",
    "    temp = X.apply(model,axis = 0, k = k)\n",
    "    out = np.array([i for i in temp]).reshape(k*X.shape[1],X.shape[0]).transpose()\n",
    "    return(pd.DataFrame(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_cv(X, y, sample_method = out_sample_cv, model=None, basis = None, alpha_list = -1, J_list = -1, cv = 5):\n",
    "    # the method is only use for SPCA model (alpha,J) and SPCA-LS model (J), not for PCA model and LS model\n",
    "    if type(alpha_list) in {int, float}:\n",
    "        alpha_list = [alpha_list]\n",
    "    if type(J_list) in {int, float}:\n",
    "        J_list = [J_list]\n",
    "        \n",
    "    if alpha_list != [-1] and J_list != [-1]:\n",
    "        # case for scpa model\n",
    "        res = pd.DataFrame([[a,J] for a in alpha_list for J in J_list],columns=['alpha','J'])\n",
    "    \n",
    "        final_par,final_loss = res.iloc[0,:],-1\n",
    "        for item in range(res.shape[0]):\n",
    "            X_expand = basis_transform(X, k = res.iloc[item,1])\n",
    "            run_model = model(sigma = res.iloc[item,0],fit_intercept = False)\n",
    "\n",
    "            loss = 0\n",
    "            for i in range(y.shape[1]):\n",
    "                yi = y[i]\n",
    "                loss += sample_method(X_expand,yi,run_model,cv)\n",
    "            if final_loss < 0 or final_loss > loss:\n",
    "                final_par,final_loss = res.iloc[item,:],loss\n",
    "    elif alpha_list == [-1]:\n",
    "        # case for spca-ls model (model = sklearn.linearRegression)\n",
    "        res = pd.DataFrame(J_list, columns=['J'])\n",
    "        \n",
    "        final_par,final_loss = res.iloc[0,:],-1\n",
    "        for item in range(res.shape[0]):\n",
    "            X_expand = basis_transform(X, k=res.iloc[item,0])\n",
    "            run_model = model(fit_intercept = False)\n",
    "\n",
    "            loss = 0\n",
    "            for i in range(y.shape[1]):\n",
    "                yi = y[i]\n",
    "                loss += sample_method(X_expand,yi,run_model,cv)\n",
    "            if final_loss < 0 or final_loss > loss:\n",
    "                final_par,final_loss = res.iloc[item,:],loss\n",
    "    else:\n",
    "        final_par = -1\n",
    "    return(final_par)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 131\n",
    "T = 480\n",
    "C_list = [i/50 for i in range(1,5)] + [i/10 for i in range(1,11)] + [i for i in range(2,6)]\n",
    "alpha_list = [np.sqrt(T/np.log(N*T))*C for C in C_list]\n",
    "J_list = [i+1 for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>-0.694602</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.305187</td>\n",
       "      <td>0.244695</td>\n",
       "      <td>-0.163255</td>\n",
       "      <td>0.198857</td>\n",
       "      <td>0.101344</td>\n",
       "      <td>0.079756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>241</td>\n",
       "      <td>-0.605469</td>\n",
       "      <td>-0.116519</td>\n",
       "      <td>-0.142423</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>-0.020608</td>\n",
       "      <td>-0.368652</td>\n",
       "      <td>0.191678</td>\n",
       "      <td>-0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>-0.409218</td>\n",
       "      <td>0.020962</td>\n",
       "      <td>-0.158319</td>\n",
       "      <td>-0.168234</td>\n",
       "      <td>0.169056</td>\n",
       "      <td>-0.122685</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>-0.221226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>243</td>\n",
       "      <td>-0.445416</td>\n",
       "      <td>-0.077201</td>\n",
       "      <td>-0.070987</td>\n",
       "      <td>-0.090584</td>\n",
       "      <td>0.109874</td>\n",
       "      <td>-0.142151</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>0.100558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>244</td>\n",
       "      <td>-0.403030</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>-0.129042</td>\n",
       "      <td>-0.275598</td>\n",
       "      <td>0.357499</td>\n",
       "      <td>-0.205591</td>\n",
       "      <td>-0.097363</td>\n",
       "      <td>0.156813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>475</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>-0.013741</td>\n",
       "      <td>0.152269</td>\n",
       "      <td>-0.029489</td>\n",
       "      <td>0.433522</td>\n",
       "      <td>-0.151863</td>\n",
       "      <td>0.074537</td>\n",
       "      <td>-0.002530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>476</td>\n",
       "      <td>-0.134700</td>\n",
       "      <td>0.129094</td>\n",
       "      <td>0.041514</td>\n",
       "      <td>0.183898</td>\n",
       "      <td>0.215773</td>\n",
       "      <td>0.128569</td>\n",
       "      <td>-0.060284</td>\n",
       "      <td>-0.245117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>477</td>\n",
       "      <td>-0.098441</td>\n",
       "      <td>0.172306</td>\n",
       "      <td>-0.175540</td>\n",
       "      <td>0.276649</td>\n",
       "      <td>0.188795</td>\n",
       "      <td>-0.234770</td>\n",
       "      <td>-0.107363</td>\n",
       "      <td>-0.434911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>478</td>\n",
       "      <td>-0.253172</td>\n",
       "      <td>0.136358</td>\n",
       "      <td>0.163368</td>\n",
       "      <td>0.139089</td>\n",
       "      <td>0.203435</td>\n",
       "      <td>0.045756</td>\n",
       "      <td>0.146176</td>\n",
       "      <td>-0.257954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>479</td>\n",
       "      <td>-0.112251</td>\n",
       "      <td>-0.087046</td>\n",
       "      <td>0.243441</td>\n",
       "      <td>0.193878</td>\n",
       "      <td>0.207911</td>\n",
       "      <td>-0.247160</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>-0.254351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index        F1        F2        F3       F4         F5        F6  \\\n",
       "0      240 -0.694602  0.010622  0.305187  0.244695 -0.163255  0.198857   \n",
       "1      241 -0.605469 -0.116519 -0.142423  0.100263 -0.020608 -0.368652   \n",
       "2      242 -0.409218  0.020962 -0.158319 -0.168234  0.169056 -0.122685   \n",
       "3      243 -0.445416 -0.077201 -0.070987 -0.090584  0.109874 -0.142151   \n",
       "4      244 -0.403030  0.031000 -0.129042 -0.275598  0.357499 -0.205591   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "235    475  0.012119 -0.013741  0.152269 -0.029489  0.433522 -0.151863   \n",
       "236    476 -0.134700  0.129094  0.041514  0.183898  0.215773  0.128569   \n",
       "237    477 -0.098441  0.172306 -0.175540  0.276649  0.188795 -0.234770   \n",
       "238    478 -0.253172  0.136358  0.163368  0.139089  0.203435  0.045756   \n",
       "239    479 -0.112251 -0.087046  0.243441  0.193878  0.207911 -0.247160   \n",
       "\n",
       "           F7        F8  \n",
       "0    0.101344  0.079756  \n",
       "1    0.191678 -0.002403  \n",
       "2    0.000924 -0.221226  \n",
       "3    0.025854  0.100558  \n",
       "4   -0.097363  0.156813  \n",
       "..        ...       ...  \n",
       "235  0.074537 -0.002530  \n",
       "236 -0.060284 -0.245117  \n",
       "237 -0.107363 -0.434911  \n",
       "238  0.146176 -0.257954  \n",
       "239  0.075256 -0.254351  \n",
       "\n",
       "[240 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_month.shape\n",
    "y_month.shape\n",
    "pd.DataFrame(x_month[240:480]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# par_out = grid_cv(x_month,y_month[1],out_sample_cv,MyHuberLoss.HuberRegressor,\\\n",
    "#         polynomial_basis,[0.1,0.2],3)\n",
    "X_df,Y_df = pd.DataFrame(x_month[239:479]).reset_index().drop(columns='index'),pd.DataFrame(y_month[239:479]).reset_index().drop(columns='index')\n",
    "par_out_spca = grid_cv(X_df,Y_df,out_sample_cv_parallel,MyHuberLoss.HuberRegressor,polynomial_basis,alpha_list,J_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use parameters generated by cross validation to form model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmented_factor_spca(y=None,obs_factors=None,alpha=1,J=1,start=0,end=None):\n",
    "    # y is a pd.DataFrame with samples at row and features at column\n",
    "    # obs_facotors is a pd.DataFrame with samples at row and features at column\n",
    "    X = basis_transform(obs_factors,k=J)\n",
    "    def robust_fit(y):\n",
    "        return(MyHuberLoss.HuberRegressor(sigma=alpha,fit_intercept=False)\\\n",
    "               .fit(X.iloc[start:end,:], y).predict(X.iloc[start:end,:]))\n",
    "    \n",
    "    origin_y = y.iloc[start:end,:]\n",
    "    pred_robust_df = origin_y.apply(robust_fit)\n",
    "    pred_sigma = pred_robust_df.cov()\n",
    "\n",
    "    K,N= obs_factors.shape[1] , origin_y.shape[1]\n",
    "    T = origin_y.shape[0]\n",
    "    \n",
    "    pred_lambda= PCA(n_components=K,whiten=True).fit(pred_robust_df).components_*(N**0.5)\n",
    "    pred_g = np.matmul(np.array(pred_robust_df),pred_lambda.transpose())/N\n",
    "    pred_f = np.matmul(np.array(origin_y),pred_lambda.transpose())/N\n",
    "    pred_gamma = pred_f - pred_g\n",
    "    \n",
    "    res_dict = {'lambda': pred_lambda, 'g':pred_g , 'f': pred_f, 'gamma': pred_gamma}\n",
    "    return(res_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurt_raw = Y_df.apply(kurtosis,axis=0,fisher = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_factors = X_df\n",
    "X = basis_transform(obs_factors,k=int(par_out_spca['J']))\n",
    "def robust_fit(y):\n",
    "    return(MyHuberLoss.HuberRegressor(sigma=par_out_spca['alpha'],fit_intercept=False).fit(X, y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = Y_df.apply(robust_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "kurt_new = pd.DataFrame(pred_y).apply(kurtosis,axis=0,fisher = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAE/CAYAAACXYc3kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3df7RldV3/8edLQEFFELlOI79G0a8/+uFoI+kSC1H6klTgWmZZGRY5VLrSpd9ytL5JrSxchki/VAhjTAVJRUgsHZHiy7cCB5z44dgXwkEZBmYUEDDEhnl//9h77Hi5d+bcO3fvc+65z8daZ929P/vXe58f7/s+n73P3qkqJEmS1L1HjDoASZKkpcLCS5IkqScWXpIkST2x8JIkSeqJhZckSVJPLLwkSZJ6YuG1hCSpJE+d57IvTHJTkvuTnLTQse2pPdm3PdzusiRXJLkvyRlJ3pbkr/qOQ9L3SuOvk9yd5OpRx7OTuUp7jzqApSLJJmAZsB14CPgS8EHg7KraMcTyK4CvAPtU1fbOAp3dHwB/XlVnjWDbI5HkNcCvVtXRu5htNfB14HE17aJ4Y/CaSZ1ZBDntaOA44NCq+laSY4APVdWhHWxrpMxVi4s9Xv36qaraHzgCOB14C3DuaEMa2hHAjfNZMMkeFfh7unzHjgC+ND2RSUvEOOe0I4BNVfWthVjZMHnIXKWhVJWPHh7AJuCl09qOAnYAP9COnwB8EbgX+Bpw2sC8XwUKuL99vAA4Evg88A2abzIfBg7cRQwF/CZwSzv/u4BHDEz/FWAjcDfwGeCItv0/2jgfaLf9KOBJwCXAXcDNwGsH1nMa8DHgQ+2+/CpNkb+mXdc3gAuBg2aJ8xjgNpokfgfwN237a9tt3dVu+0nD7Fsbz4cG5l3Rzr93O/6adrn7aL71/QLwTODbNN/k7wfumSHO84D/Ar7TzvPSwW3N8pq9BrgS+JP2ef4K8BMD6zyA5h/XFmAz8IfAXu20pwL/BHyz3cePtu0BzgS2ts/39bTvKR8+unowHjntrHa99wLXAC9q20+Z9vl9F03+2jGwvSexi7w0kCdOaWO9YobtH4O5ylw118/OqANYKg9mSFJt+1eBX2+HjwF+sE0GPwTcCZzUTvueD2Db9lSarvRHAVPAFcB7dhFDAZcDBwGHA/+Ppnsa4MQ2UTyT5hD07wL/PFv87bb+EtgXWAlsA45tp53WfshPavdlP+ANwL8Ch7bxvh84f5Y4j6E5fPHOdt79gGPbD/Bz27Y/YyAR7mbfvptgpj+XwGPaBPD0dtpy4Pvb4dcAV+7mdT0P+MOB8e9ua5bX7DXtc/NaYC/g14HbgbTTL2qfm8cATwSuBk5tp50P/E77nO4LHN22/0+afzoH0iS2ZwLLR/2e9zHZj+k5YaC9z5z2i8AT2s/ym2mKn33bad/z+W1juW3a8rPmpYH4Pth+HvebYfvHYK4yV83x4aHG0bud5gNIVf1jVV1fVTuq6jqaN++PzbZgVd1cVeuq6sGq2ga8e1fzt95ZVXdV1VeB9wCvatt/DfjjqtpYzTH+PwJWJjli+gqSHAa8EHhLVX27qjYAfwX80sBs/1JVn2z35YF2/b9TVbdV1YM0H/pX7KJrfgfw9nbfHqD5ZveBqrq2Xf6twAvacxN2t2+7swP4gST7VdWWqprXIdU5uLWqzqmqh4C1NAl0WZJlwMuAN1bVt6pqK823w59rl/svmsMFT2qf9ysH2vcHnkGTFDdW1ZaO90GaTW85rao+VFXfqKrtVXUGTaHz9DnEOkxeOq39PD4wyzrMVeaqObHwGr1DaLqjSfIjSS5Psi3JN2mSwsGzLdj+SuWCJJuT3EtzaG/W+VtfGxi+laa7HZoPyVlJ7klyTxtT2vimexJwV1XdN21dg/N+7XsX4QjgooH1b6TpGl82S5zbqurb07Z5686Rqrqf5tDAbNsc3LdZVXP+x8/SPNdbklya5Bm7W24P3TGw/f9sBx9L8xzt08ax83l6P823SYDfpnlNrk5yY5JfadfxeeDPgb8AtiY5O8njOt4HaTa95bQk/yvJxiTfbD8vB+xq/hkMk5em57LpzFXmqjmx8BqhJM+j+TDu/DbwEZrzAQ6rqgOA99G8eaHpBp7uj9r2H6yqx9F0u2eG+QYdNjB8OM23U2gSwalVdeDAY7+q+ucZ1nE7cFCS/aeta/PA+PR4v0ZzfsDg+vetqs3MbPryt9N82AFI8hiaQwyDy8+2b98CHj0w7fu+Z0NVn6mq42i+zX0ZOGeWGOZqrst/DXgQOHjgOXpcVX1/G+cdVfXaqnoScCrwlzt/ll5Vf1pVPww8C/gfwG/tYezSnPWZ05K8iOYf/CuBx1fVgTTnFM2WA2fa3jB5aXefY3OVuWpOLLxGIMnjkvwkcAHNMfbr20n70/QkfTvJUcDPDyy2jaab+SkDbfvTnAj5zSSHMNwb+LeSPL49XPgG4KNt+/uAtyb5/jbGA5L8zEwrqKqvAf8M/HGSfZP8EM0JqB/axXbfB7xj56HLJFNJThwi3p3OB345ycokj6JJ0FdV1aYh9m0D8KNJDk9yAE3XP20cy5Kc2CbHB2mez50/hb8TODTJI+cQ56CZXrNZtV3unwXOaN8jj0hyZJIfa2P9mSQ7fwp/N02y3JHkeW3Pwj40ifvbA/sgdW5EOW1/mvOrtgF7J/k9YFe9J3cCT2hzwE57mpdmYq4yV+2ShVe//i7JfTTfFn6H5vyFXx6Y/hvAH7Tz/B7NL2yA73bzvgP4v23X7vOB36c5gfObwKXAJ4aI4WKakxs3tMuc267/IpoTRC9ou/hvAH5iF+t5Fc0JmbfTnGT59qr63C7mP4vmm+9n2/37V+BHhoiXNr7PAf8b+DjNr2iO5L/PJ9jdvq2jSWzXtdM/NbDMI4A3tftxF835JL/eTvs8zSU07kjy9WFjHYh5ptdsd34JeCTNNZHupvl16PJ22vOAq5LcT/NcvqGqbqH5Z3NOO/+tNIc13jXXeKV5GGVO+wzwDzQnp99K80981sOCVfVlmqLolnZ7T2IP89Is2zFXmat2aeevEyRJktQxe7wkSZJ6YuElSZLUEwsvSZKknlh4SZIk9cTCS5IkqSfjfCf17zr44INrxYoVow5DUk+uueaar1fV1KjjWAjmL2np2VUOWxSF14oVK1i/fv2ow5DUkyS37n6uxcH8JS09u8phHmqUJEnqiYWXJElSTyy8JEmSemLhJUmS1BMLL0mSpJ5YeEmSJPXEwkuSJKknFl6SJEk9sfCSJEnqiYWXJElSTyy8JEmSerIo7tU4CivWXPqwtk2nnzCCSCRpfMyUG8H8KA3LHi9JkqSeWHhJkiT1xMJLkqZJsm+Sq5P8W5Ibk/x+235ekq8k2dA+Vo46VkmLi+d4SdLDPQgcW1X3J9kHuDLJ37fTfquqPjbC2CQtYhZekjRNVRVwfzu6T/uo0UUkaVJ4qFGSZpBkryQbgK3Auqq6qp30jiTXJTkzyaNGGKKkRcjCS5JmUFUPVdVK4FDgqCQ/ALwVeAbwPOAg4C0zLZtkdZL1SdZv27att5gljT8LL0nahaq6B7gcOL6qtlTjQeCvgaNmWebsqlpVVaumpqb6DFfSmLPwkqRpkkwlObAd3g84DvhykuVtW4CTgBtGF6WkxciT6yXp4ZYDa5PsRfMF9cKq+lSSzyeZAgJsAH5tlEFKWnwsvCRpmqq6DnjODO3HjiAcSRPEQ42SJEk9sfCSJEnqiYWXJElSTzo9xyvJJuA+4CFge1WtSnIQ8FFgBbAJeGVV3d1lHJIkSeOgjx6vF1fVyqpa1Y6vAS6rqqcBl7XjkiRJE28UhxpPBNa2w2tproUjSZI08bouvAr4bJJrkqxu25ZV1ZZ2+A5gWccxSJIkjYWur+N1dFVtTvJEYF2SLw9OrKpKUjMt2BZqqwEOP/zwjsOUJEnqXqc9XlW1uf27FbiI5r5mdw7cdmM5sHWWZb3XmSRJmiidFV5JHpNk/53DwI/T3NfsEuDkdraTgYu7ikGSJGmcdHmocRlwUXMvWfYGPlJV/5DkC8CFSU4BbgVe2WEMkiRJY6OzwquqbgGePUP7N4CXdLVdSZKkceWV6yVJknpi4SVJktQTCy9JkqSeWHhJkiT1xMJLkiSpJxZekiRJPbHwkiRJ6omFlyRJUk8svCRJknpi4SVJktQTCy9JkqSeWHhJkiT1xMJLkiSpJxZekiRJPbHwkiRJ6omFlyRNk2TfJFcn+bckNyb5/bb9yUmuSnJzko8meeSoY5W0uFh4SdLDPQgcW1XPBlYCxyd5PvBO4MyqeipwN3DKCGOUtAhZeEnSNNW4vx3dp30UcCzwsbZ9LXDSCMKTtIhZeEnSDJLslWQDsBVYB/wHcE9VbW9nuQ04ZFTxSVqcLLwkaQZV9VBVrQQOBY4CnjHssklWJ1mfZP22bds6i1HS4mPhJUm7UFX3AJcDLwAOTLJ3O+lQYPMsy5xdVauqatXU1FRPkUpaDCy8JGmaJFNJDmyH9wOOAzbSFGCvaGc7Gbh4NBFKWqz23v0skrTkLAfWJtmL5gvqhVX1qSRfAi5I8ofAF4FzRxmkpMXHwkuSpqmq64DnzNB+C835XpI0Lx5qlCRJ6omFlyRJUk881ChJepgVay4ddQjSRLLHS5IkqScWXpIkST2x8JIkSeqJhZckSVJPLLwkSZJ6YuElSZLUEwsvSZKknlh4SZIk9cTCS5IkqScWXpIkST2x8JIkSeqJhZckSVJPOi+8kuyV5ItJPtWOPznJVUluTvLRJI/sOgZJkqRx0EeP1xuAjQPj7wTOrKqnAncDp/QQgyRJ0sjt3eXKkxwKnAC8A3hTkgDHAj/fzrIWOA14b5dxSJK6tWLNpTO2bzr9hJ4jkcZb1z1e7wF+G9jRjj8BuKeqtrfjtwGHdByDJEnSWOis8Eryk8DWqrpmnsuvTrI+yfpt27YtcHSSJEn967LH64XATyfZBFxAc4jxLODAJDsPcR4KbJ5p4ao6u6pWVdWqqampDsOUJEnqR2eFV1W9taoOraoVwM8Bn6+qXwAuB17RznYycHFXMUiSJI2TUVzH6y00J9rfTHPO17kjiEGSJKl3nf6qcaeq+kfgH9vhW4Cj+tiuJEnSOPHK9ZIkST2x8JIkSeqJhZckSVJPLLwkaZokhyW5PMmXktyY5A1t+2lJNifZ0D5eNupYJS0uvZxcL0mLzHbgzVV1bZL9gWuSrGunnVlVfzLC2CQtYhZekjRNVW0BtrTD9yXZiLc3k7QAPNQoSbuQZAXwHOCqtun1Sa5L8oEkjx9ZYJIWJQsvSZpFkscCHwfeWFX3Au8FjgRW0vSInTHLct5rVtKMLLwkaQZJ9qEpuj5cVZ8AqKo7q+qhqtoBnMMsF4P2XrOSZmPhJUnTJAnN7cw2VtW7B9qXD8z2cuCGvmOTtLh5cr0kPdwLgVcD1yfZ0La9DXhVkpVAAZuAU0cTnqTFysJLkqapqiuBzDDp033HImmyeKhRkiSpJxZekiRJPbHwkiRJ6omFlyRJUk8svCRJknpi4SVJktQTCy9JkqSeWHhJkiT1xMJLkiSpJxZekiRJPbHwkiRJ6omFlyRJUk8svCRJknpi4SVJktSToQqvJD/YdSCS1AXzl6RxMmyP118muTrJbyQ5oNOIJGlhmb8kjY2hCq+qehHwC8BhwDVJPpLkuE4jk6QFYP6SNE72HnbGqropye8C64E/BZ6TJMDbquoTXQUoSXvK/DU6K9Zc+rC2TaefMIJIpPEw7DleP5TkTGAjcCzwU1X1zHb4zA7jk6Q9Yv6SNE6G7fH6M+CvaL4dPrCzsapub79FStK4Mn9JGhvDFl4nAA9U1UMASR4B7FtV/1lVf9NZdJK058xfksbGsL9q/Byw38D4o9s2SRp35i9JY2PYwmvfqrp/50g7/OhuQpKkBWX+kjQ2hi28vpXkuTtHkvww8MAu5pekcWH+kjQ2hj3H643A3ya5HQjwfcDPdhaVJC0c85eksTFU4VVVX0jyDODpbdO/V9V/dReWJC0M85ekcTL0BVSB5wEr2mWem4Sq+mAnUUnSwjJ/SRoLQxVeSf4GOBLYADzUNhcwa+JKsi9wBfCodjsfq6q3J3kycAHwBOAa4NVV9Z1574Ek7cI889dh7fRl7bxnV9VZSQ4CPkpTxG0CXllVd3cWvKSJM2yP1yrgWVVVc1j3g8CxVXV/kn2AK5P8PfAm4MyquiDJ+4BTgPfOKWpJGt588td24M1VdW2S/Wnu8bgOeA1wWVWdnmQNsAZ4y4JHLGliDfurxhtoTkgdWjV2/oR7n/ZRNLfp+FjbvhY4aS7rlaQ5mk/+2lJV17bD99HcbugQ4ESavAXmL0nzMGyP18HAl5JcTdOTBUBV/fSuFkqyF83hxKcCfwH8B3BPVW1vZ7mNJplJUlfmlb92SrICeA5wFbCsqra0k+6gORQpSUMbtvA6bT4rb2/RsTLJgcBFwDOGXTbJamA1wOGHHz6fzUsSzDN/ASR5LPBx4I1VdW+S706rqkoy4+FL85ek2Qx1qLGq/onmRNJ92uEvANcOu5Gquge4HHgBcGCSnQXfocDmWZY5u6pWVdWqqampYTclSd9jvvmrPTf148CHq+oTbfOdSZa305cDW2fZpvlL0oyGKrySvJbmvKz3t02HAJ/czTJTbU8XSfYDjqM5T+Jy4BXtbCcDF889bEkazjzzV4BzgY1V9e6BSZfQ5C0wf0mah2FPrn8d8ELgXoCqugl44m6WWQ5cnuQ6mm+Y66rqUzS/AHpTkptpLilx7nwCl6QhzSd/vRB4NXBskg3t42XA6cBxSW4CXtqOS9LQhj3H68Gq+s7O8xvaQ4W7/Gl2VV1Hc0Lq9PZbgKPmGKckzdd88teVNLcXmslLFjY8SUvJsD1e/5TkbcB+SY4D/hb4u+7CkqQFY/6SNDaGLbzWANuA64FTgU8Dv9tVUJK0gMxfksbGsDfJ3gGc0z4kadEwf0kaJ8Peq/ErzHBORFU9ZcEjkqQFZP6SNE7mcq/GnfYFfgY4aOHDkaQFZ/6SNDaGvYDqNwYem6vqPcAJHccmSXvM/CVpnAx7qPG5A6OPoPkGOWxvmSSNjPlL0jgZNvmcMTC8neb2G69c8GgkaeGZvySNjWF/1fjirgORpC6YvySNk2EPNb5pV9On3ctMksaG+UvSOJnLrxqfR3ODWICfAq4GbuoiKElaQOYvSWNj2MLrUOC5VXUfQJLTgEur6he7CkySFoj5S9LYGPaWQcuA7wyMf6dtk6RxZ/6SNDaG7fH6IHB1kova8ZOAtd2EJEkLyvwlaWwM+6vGdyT5e+BFbdMvV9UXuwtrPK1Yc+mM7ZtO91qM0rgyf0kaJ8MeagR4NHBvVZ0F3JbkyR3FJEkLzfwlaSwMVXgleTvwFuCtbdM+wIe6CkqSFor5S9I4GbbH6+XATwPfAqiq24H9uwpKkhaQ+UvS2Bi28PpOVRVQAEke011IkrSgzF+SxsawhdeFSd4PHJjktcDngHO6C0uSFoz5S9LYGPZXjX+S5DjgXuDpwO9V1bpOI5OkBWD+kjROdlt4JdkL+Fx7o1mTlaRFw/wladzs9lBjVT0E7EhyQA/xSNKCMX9JGjfDXrn+fuD6JOtofxkEUFW/2UlUkrRwzF+Sxsawhdcn2ockLTbmL0ljY5eFV5LDq+qrVeV9zSQtKuYvSeNod+d4fXLnQJKPdxyLJC0k85eksbO7wisDw0/pMhBJWmB7lL+SfCDJ1iQ3DLSdlmRzkg3t42ULEqmkJWN3hVfNMixJ425P89d5wPEztJ9ZVSvbx6fnFZmkJWt3J9c/O8m9NN8c92uHacerqh7XaXSSNH97lL+q6ookK7oNUdJSs8vCq6r26isQSVpIHeav1yf5JWA98Oaquruj7UiaQMPeq1GSBO8FjgRWAluAM2aaKcnqJOuTrN+2bVuf8UkacxZekjSkqrqzqh6qqh00N9o+apb5zq6qVVW1ampqqt8gJY01Cy9JGlKS5QOjLwdumG1eSZrJsFeul6QlJcn5wDHAwUluA94OHJNkJc2vJDcBp44sQEmLkoWXJM2gql41Q/O5vQciaaJ4qFGSJKknFl6SJEk98VCjJC1xK9ZcOuoQpCWjsx6vJIcluTzJl5LcmOQNbftBSdYluan9+/iuYpAkSRonXR5q3E5zVednAc8HXpfkWcAa4LKqehpwWTsuSZI08TorvKpqS1Vd2w7fB2wEDgFOBNa2s60FTuoqBkmSpHHSy8n17Y1mnwNcBSyrqi3tpDuAZX3EIEmSNGqdF15JHgt8HHhjVd07OK2qiuZChDMt573OJEnSROm08EqyD03R9eGq+kTbfOfO2260f7fOtKz3OpMkSZOmy181huYqzxur6t0Dky4BTm6HTwYu7ioGSZKkcdLldbxeCLwauD7JhrbtbcDpwIVJTgFuBV7ZYQySJEljo7PCq6quBDLL5Jd0tV1JkqRx5ZXrF8BsV33edPoJPUciSZLGmfdqlCRJ6omFlyRJUk8svCRJknpi4SVJktQTCy9JkqSeWHhJkiT1xMJLkiSpJxZekiRJPbHwkiRJ6omFlyRJUk8svCRJknpi4SVJktQTCy9JkqSeWHhJkiT1xMJLkmaQ5ANJtia5YaDtoCTrktzU/n38KGOUtPhYeEnSzM4Djp/Wtga4rKqeBlzWjkvS0Cy8JGkGVXUFcNe05hOBte3wWuCkXoOStOhZeEnS8JZV1ZZ2+A5g2SiDkbT4WHhJ0jxUVQE107Qkq5OsT7J+27ZtPUcmaZxZeEnS8O5Mshyg/bt1ppmq6uyqWlVVq6ampnoNUNJ4s/CSpOFdApzcDp8MXDzCWCQtQhZekjSDJOcD/wI8PcltSU4BTgeOS3IT8NJ2XJKGtveoA5CkcVRVr5pl0kt6DUTSRLHHS5IkqScWXpIkST2x8JIkSeqJhZckSVJPLLwkSZJ6YuElSZLUEwsvSZKknlh4SZIk9cTCS5IkqSdeuX4EVqy59GFtm04/YQSRSJKkPtnjJUmS1BMLL0mSpJ5YeEmSJPXEwkuSJKknFl6SJEk96azwSvKBJFuT3DDQdlCSdUluav8+vqvtS5IkjZsue7zOA46f1rYGuKyqngZc1o5LkiQtCZ0VXlV1BXDXtOYTgbXt8FrgpK62L0mSNG76PsdrWVVtaYfvAJb1vH1JkqSRGdmV66uqktRs05OsBlYDHH744b3FtZBmukK9JElauvru8bozyXKA9u/W2WasqrOralVVrZqamuotQEmSpK70XXhdApzcDp8MXNzz9iVJkkamy8tJnA/8C/D0JLclOQU4HTguyU3AS9txSZKkJaGzc7yq6lWzTHpJV9uUJEkaZ165XpIkqScWXpIkST2x8JIkSerJyK7jJUmLVZJNwH3AQ8D2qlo12ogkLRYWXpI0Py+uqq+POghJi4uHGiVJknpi4SVJc1fAZ5Nc097eTJKG4qFGSZq7o6tqc5InAuuSfLmqrtg5cRLuNSupG/Z4SdIcVdXm9u9W4CLgqGnTvdespBlZeEnSHCR5TJL9dw4DPw7cMNqoJC0WHmqUpLlZBlyUBJoc+pGq+ofRhiRpsbDwkqQ5qKpbgGePOg5Ji5OHGiVJknpi4SVJktQTCy9JkqSeWHhJkiT1xMJLkiSpJxZekiRJPbHwkiRJ6omFlyRJUk8svCRJknpi4SVJktQTCy9JkqSeWHhJkiT1xJtkj4kVay6dsX3T6Sf0HIkkSeqKPV6SJEk9sfCSJEnqiYWXJElSTzzHa8J4rpikcWee0lJmj5ckSVJPLLwkSZJ6YuElSZLUEwsvSZKknlh4SZIk9cTCS5IkqScWXpIkST3xOl6StETMdv0sSf2xx0uSJKkn9niNuYW6wvNM61mIdcxnPZIkLVUj6fFKcnySf09yc5I1o4hBkubLHCZpvnovvJLsBfwF8BPAs4BXJXlW33FI0nyYwyTtiVH0eB0F3FxVt1TVd4ALgBNHEIckzYc5TNK8jaLwOgT42sD4bW2bJC0G5jBJ8za2J9cnWQ2sbkfvT/LvQy56MPD1bqIaH3nnnu9n3rlgsXRpKbyeS2EfYW77eUSXgXRtD/IXLI33w4z72HEuGYWl8FrC0tjPue7jrDlsFIXXZuCwgfFD27bvUVVnA2fPdeVJ1lfVqvmHtzi4n5NjKewjTNR+7jaHzTd/wUQ9T7NaCvsI7uckWch9HMWhxi8AT0vy5CSPBH4OuGQEcUjSfJjDJM1b7z1eVbU9yeuBzwB7AR+oqhv7jkOS5sMcJmlPjOQcr6r6NPDpjlY/r+79Rcj9nBxLYR9hgvbTHLbHlsI+gvs5SRZsH1NVC7UuSZIk7YL3apQkSerJRBVeS+U2Hkk2Jbk+yYYk60cdz0JI8oEkW5PcMNB2UJJ1SW5q/z5+lDEuhFn287Qkm9vXc0OSl40yxj2V5LAklyf5UpIbk7yhbZ+413Mhmb8Wt6WQw5ZC/oLuc9jEFF5L8DYeL66qlRP0E97zgOOnta0BLquqpwGXteOL3Xk8fD8Bzmxfz5Xt+UOL2XbgzVX1LOD5wOvaz+Ikvp4Lwvw1Ec5j8nPYeUx+/oKOc9jEFF54G49FraquAO6a1nwisLYdXguc1GtQHZhlPydKVW2pqmvb4fuAjTRXdp+413MBmb8WuaWQw5ZC/oLuc9gkFV5L6TYeBXw2yTXtFbIn1bKq2tIO3wEsG2UwHXt9kuvarvxFfThiUJIVwHOAq1har+dcmb8m01J5z09k/oJuctgkFV5LydFV9VyawxKvS/Kjow6oa9X8/HZSf4L7XuBIYCWwBThjtOEsjCSPBT4OvLGq7h2cNuGvp3ZtyeUvmOj3/ETmL+guh01S4TXUrYgmQVVtbv9uBS6iOUwxie5Mshyg/bt1xPF0oqrurKqHqmoHcA4T8Hom2YcmYX24qj7RNi+J13OezF+TaeLf85OYv6DbHDZJhdeSuI1Hksck2X/nMPDjwA27XmrRugQ4uR0+Gbh4hLF0ZucHufVyFvnrmSTAucDGqnr3wKQl8XrOk/lrMk38e37S8hd0n8Mm6gKq7c9Y38N/38bjHSMOacEleQrNt0Ro7jzwkUnYzyTnA8fQ3AH+TuDtwCeBC4HDgWCXNM8AAAB9SURBVFuBV1bVoj6xc5b9PIamm76ATcCpA+cRLDpJjgb+D3A9sKNtfhvNORIT9XouJPPX4rYUcthSyF/QfQ6bqMJLkiRpnE3SoUZJkqSxZuElSZLUEwsvSZKknlh4SZIk9cTCS5IkqScWXpIkST2x8JIkSeqJhZckSVJP/j8SEt+4qon+pwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(kurt_raw,range = [0,20],bins=40)\n",
    "plt.title('Data before robust fitness')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(kurt_new,range = [0,20],bins=40)\n",
    "plt.title('Data after robust fitness')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('pic/Figure6_2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
